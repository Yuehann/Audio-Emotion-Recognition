{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER-fer2013-v0.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1BEOkcxSDmiz8H12YdetOedi4c4kPnbJd",
      "authorship_tag": "ABX9TyOi25sa0H5J7djvYklHNx/9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yuehann/Audio-Emotion-Recognition/blob/master/FER_fer2013_v0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Elk3w2akkWk5"
      },
      "source": [
        "## File Mount"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVk2qA__dRO1",
        "outputId": "33eb5d22-4726-40a7-bf8d-14f82b24868c"
      },
      "source": [
        "# To mount google drive when using colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvfoyBRWeOZi"
      },
      "source": [
        "# Path for input files in google drive mounted\n",
        "path = '/content/drive/My Drive/Colab Notebooks/FYP/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0JQ-fQ9chyc"
      },
      "source": [
        "## Data Preprocessing - Fer 2013 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CpwQ3ONcWZi",
        "outputId": "1bbb7084-1f21-4401-9605-c895aa70de93"
      },
      "source": [
        "# create data and label for FER2013\n",
        "# labels: 0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral\n",
        "import csv\n",
        "import os\n",
        "import numpy as np\n",
        "import h5py\n",
        "\n",
        "file = path + 'Data-Fer2013/fer2013.csv'\n",
        "\n",
        "# Creat the list to store the data and label information\n",
        "Training_x = []\n",
        "Training_y = []\n",
        "PublicTest_x = []\n",
        "PublicTest_y = []\n",
        "PrivateTest_x = []\n",
        "PrivateTest_y = []\n",
        "\n",
        "datapath = path + 'Data-Fer2013/data-fer2013.h5'\n",
        "\n",
        "with open(file,'r') as csvin:\n",
        "    data=csv.reader(csvin)\n",
        "    for row in data:\n",
        "        if row[-1] == 'Training':\n",
        "            temp_list = []\n",
        "            for pixel in row[1].split( ):\n",
        "                temp_list.append(int(pixel))\n",
        "            I = np.asarray(temp_list)\n",
        "            Training_y.append(int(row[0]))\n",
        "            Training_x.append(I.tolist())\n",
        "\n",
        "        if row[-1] == \"PublicTest\" :\n",
        "            temp_list = []\n",
        "            for pixel in row[1].split( ):\n",
        "                temp_list.append(int(pixel))\n",
        "            I = np.asarray(temp_list)\n",
        "            PublicTest_y.append(int(row[0]))\n",
        "            PublicTest_x.append(I.tolist())\n",
        "\n",
        "        if row[-1] == 'PrivateTest':\n",
        "            temp_list = []\n",
        "            for pixel in row[1].split( ):\n",
        "                temp_list.append(int(pixel))\n",
        "            I = np.asarray(temp_list)\n",
        "\n",
        "            PrivateTest_y.append(int(row[0]))\n",
        "            PrivateTest_x.append(I.tolist())\n",
        "\n",
        "print(np.shape(Training_x))\n",
        "print(np.shape(PublicTest_x))\n",
        "print(np.shape(PrivateTest_x))\n",
        "\n",
        "datafile = h5py.File(datapath, 'w')\n",
        "datafile.create_dataset(\"Training_pixel\", dtype = 'uint8', data=Training_x)\n",
        "datafile.create_dataset(\"Training_label\", dtype = 'int64', data=Training_y)\n",
        "datafile.create_dataset(\"PublicTest_pixel\", dtype = 'uint8', data=PublicTest_x)\n",
        "datafile.create_dataset(\"PublicTest_label\", dtype = 'int64', data=PublicTest_y)\n",
        "datafile.create_dataset(\"PrivateTest_pixel\", dtype = 'uint8', data=PrivateTest_x)\n",
        "datafile.create_dataset(\"PrivateTest_label\", dtype = 'int64', data=PrivateTest_y)\n",
        "datafile.close()\n",
        "\n",
        "print(\"Save data finish!!!\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28709, 2304)\n",
            "(3589, 2304)\n",
            "(3589, 2304)\n",
            "Save data finish!!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pg6bbTgVj43J"
      },
      "source": [
        "## VGG Model Build"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_S0ATNihXun"
      },
      "source": [
        "'''VGG11/13/16/19 in Pytorch.'''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "cfg = {\n",
        "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
        "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
        "}\n",
        "\n",
        "\n",
        "class VGG(nn.Module):\n",
        "    def __init__(self, vgg_name):\n",
        "        super(VGG, self).__init__()\n",
        "        self.features = self._make_layers(cfg[vgg_name])\n",
        "        self.classifier = nn.Linear(512, 7)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.features(x)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = F.dropout(out, p=0.5, training=self.training)\n",
        "        out = self.classifier(out)\n",
        "        return out\n",
        "\n",
        "    def _make_layers(self, cfg):\n",
        "        layers = []\n",
        "        in_channels = 3\n",
        "        for x in cfg:\n",
        "            if x == 'M':\n",
        "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "            else:\n",
        "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
        "                           nn.BatchNorm2d(x),\n",
        "                           nn.ReLU(inplace=True)]\n",
        "                in_channels = x\n",
        "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
        "        return nn.Sequential(*layers)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e81qasrkJ16"
      },
      "source": [
        "## Training Model (vgg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4E_kSEF5kQcW"
      },
      "source": [
        "'''Train Fer2013 with PyTorch.'''\n",
        "# 10 crop for data enhancement\n",
        "from __future__ import print_function\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torchvision\n",
        "import transforms as transforms\n",
        "import numpy as np\n",
        "import os\n",
        "import argparse\n",
        "import utils\n",
        "from fer import FER2013\n",
        "from torch.autograd import Variable\n",
        "from models import *\n",
        "\n",
        "parser = argparse.ArgumentParser(description='PyTorch Fer2013 CNN Training')\n",
        "parser.add_argument('--model', type=str, default='VGG19', help='CNN architecture')\n",
        "parser.add_argument('--dataset', type=str, default='FER2013', help='CNN architecture')\n",
        "parser.add_argument('--bs', default=128, type=int, help='learning rate')\n",
        "parser.add_argument('--lr', default=0.01, type=float, help='learning rate')\n",
        "parser.add_argument('--resume', '-r', action='store_true', help='resume from checkpoint')\n",
        "opt = parser.parse_args()\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "best_PublicTest_acc = 0  # best PublicTest accuracy\n",
        "best_PublicTest_acc_epoch = 0\n",
        "best_PrivateTest_acc = 0  # best PrivateTest accuracy\n",
        "best_PrivateTest_acc_epoch = 0\n",
        "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
        "\n",
        "learning_rate_decay_start = 80  # 50\n",
        "learning_rate_decay_every = 5 # 5\n",
        "learning_rate_decay_rate = 0.9 # 0.9\n",
        "\n",
        "cut_size = 44\n",
        "total_epoch = 250\n",
        "\n",
        "path = os.path.join(opt.dataset + '_' + opt.model)\n",
        "\n",
        "# Data\n",
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(44),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.TenCrop(cut_size),\n",
        "    transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
        "])\n",
        "\n",
        "trainset = FER2013(split = 'Training', transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=opt.bs, shuffle=True, num_workers=1)\n",
        "PublicTestset = FER2013(split = 'PublicTest', transform=transform_test)\n",
        "PublicTestloader = torch.utils.data.DataLoader(PublicTestset, batch_size=opt.bs, shuffle=False, num_workers=1)\n",
        "PrivateTestset = FER2013(split = 'PrivateTest', transform=transform_test)\n",
        "PrivateTestloader = torch.utils.data.DataLoader(PrivateTestset, batch_size=opt.bs, shuffle=False, num_workers=1)\n",
        "\n",
        "# Model\n",
        "if opt.model == 'VGG19':\n",
        "    net = VGG('VGG19')\n",
        "elif opt.model  == 'Resnet18':\n",
        "    net = ResNet18()\n",
        "\n",
        "if opt.resume:\n",
        "    # Load checkpoint.\n",
        "    print('==> Resuming from checkpoint..')\n",
        "    assert os.path.isdir(path), 'Error: no checkpoint directory found!'\n",
        "    checkpoint = torch.load(os.path.join(path,'PrivateTest_model.t7'))\n",
        "\n",
        "    net.load_state_dict(checkpoint['net'])\n",
        "    best_PublicTest_acc = checkpoint['best_PublicTest_acc']\n",
        "    best_PrivateTest_acc = checkpoint['best_PrivateTest_acc']\n",
        "    best_PrivateTest_acc_epoch = checkpoint['best_PublicTest_acc_epoch']\n",
        "    best_PrivateTest_acc_epoch = checkpoint['best_PrivateTest_acc_epoch']\n",
        "    start_epoch = checkpoint['best_PrivateTest_acc_epoch'] + 1\n",
        "else:\n",
        "    print('==> Building model..')\n",
        "\n",
        "if use_cuda:\n",
        "    net.cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=opt.lr, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "# Training\n",
        "def train(epoch):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    global Train_acc\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    if epoch > learning_rate_decay_start and learning_rate_decay_start >= 0:\n",
        "        frac = (epoch - learning_rate_decay_start) // learning_rate_decay_every\n",
        "        decay_factor = learning_rate_decay_rate ** frac\n",
        "        current_lr = opt.lr * decay_factor\n",
        "        utils.set_lr(optimizer, current_lr)  # set the decayed rate\n",
        "    else:\n",
        "        current_lr = opt.lr\n",
        "    print('learning_rate: %s' % str(current_lr))\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        if use_cuda:\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        inputs, targets = Variable(inputs), Variable(targets)\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        utils.clip_gradient(optimizer, 0.1)\n",
        "        optimizer.step()\n",
        "        train_loss += loss.data[0]\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets.data).cpu().sum()\n",
        "\n",
        "        utils.progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "            % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n",
        "    Train_acc = 100.*correct/total\n",
        "\n",
        "def PublicTest(epoch):\n",
        "    global PublicTest_acc\n",
        "    global best_PublicTest_acc\n",
        "    global best_PublicTest_acc_epoch\n",
        "    net.eval()\n",
        "    PublicTest_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(PublicTestloader):\n",
        "        bs, ncrops, c, h, w = np.shape(inputs)\n",
        "        inputs = inputs.view(-1, c, h, w)\n",
        "        if use_cuda:\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "        inputs, targets = Variable(inputs, volatile=True), Variable(targets)\n",
        "        outputs = net(inputs)\n",
        "        outputs_avg = outputs.view(bs, ncrops, -1).mean(1)  # avg over crops\n",
        "        loss = criterion(outputs_avg, targets)\n",
        "        PublicTest_loss += loss.data[0]\n",
        "        _, predicted = torch.max(outputs_avg.data, 1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets.data).cpu().sum()\n",
        "\n",
        "        utils.progress_bar(batch_idx, len(PublicTestloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "                           % (PublicTest_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n",
        "\n",
        "    # Save checkpoint.\n",
        "    PublicTest_acc = 100.*correct/total\n",
        "    if PublicTest_acc > best_PublicTest_acc:\n",
        "        print('Saving..')\n",
        "        print(\"best_PublicTest_acc: %0.3f\" % PublicTest_acc)\n",
        "        state = {\n",
        "            'net': net.state_dict() if use_cuda else net,\n",
        "            'acc': PublicTest_acc,\n",
        "            'epoch': epoch,\n",
        "        }\n",
        "        if not os.path.isdir(path):\n",
        "            os.mkdir(path)\n",
        "        torch.save(state, os.path.join(path,'PublicTest_model.t7'))\n",
        "        best_PublicTest_acc = PublicTest_acc\n",
        "        best_PublicTest_acc_epoch = epoch\n",
        "\n",
        "def PrivateTest(epoch):\n",
        "    global PrivateTest_acc\n",
        "    global best_PrivateTest_acc\n",
        "    global best_PrivateTest_acc_epoch\n",
        "    net.eval()\n",
        "    PrivateTest_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(PrivateTestloader):\n",
        "        bs, ncrops, c, h, w = np.shape(inputs)\n",
        "        inputs = inputs.view(-1, c, h, w)\n",
        "        if use_cuda:\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "        inputs, targets = Variable(inputs, volatile=True), Variable(targets)\n",
        "        outputs = net(inputs)\n",
        "        outputs_avg = outputs.view(bs, ncrops, -1).mean(1)  # avg over crops\n",
        "        loss = criterion(outputs_avg, targets)\n",
        "        PrivateTest_loss += loss.data[0]\n",
        "        _, predicted = torch.max(outputs_avg.data, 1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets.data).cpu().sum()\n",
        "\n",
        "        utils.progress_bar(batch_idx, len(PublicTestloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "            % (PrivateTest_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n",
        "    # Save checkpoint.\n",
        "    PrivateTest_acc = 100.*correct/total\n",
        "\n",
        "    if PrivateTest_acc > best_PrivateTest_acc:\n",
        "        print('Saving..')\n",
        "        print(\"best_PrivateTest_acc: %0.3f\" % PrivateTest_acc)\n",
        "        state = {\n",
        "            'net': net.state_dict() if use_cuda else net,\n",
        "\t        'best_PublicTest_acc': best_PublicTest_acc,\n",
        "            'best_PrivateTest_acc': PrivateTest_acc,\n",
        "    \t    'best_PublicTest_acc_epoch': best_PublicTest_acc_epoch,\n",
        "            'best_PrivateTest_acc_epoch': epoch,\n",
        "        }\n",
        "        if not os.path.isdir(path):\n",
        "            os.mkdir(path)\n",
        "        torch.save(state, os.path.join(path,'PrivateTest_model.t7'))\n",
        "        best_PrivateTest_acc = PrivateTest_acc\n",
        "        best_PrivateTest_acc_epoch = epoch\n",
        "\n",
        "for epoch in range(start_epoch, total_epoch):\n",
        "    train(epoch)\n",
        "    PublicTest(epoch)\n",
        "    PrivateTest(epoch)\n",
        "\n",
        "print(\"best_PublicTest_acc: %0.3f\" % best_PublicTest_acc)\n",
        "print(\"best_PublicTest_acc_epoch: %d\" % best_PublicTest_acc_epoch)\n",
        "print(\"best_PrivateTest_acc: %0.3f\" % best_PrivateTest_acc)\n",
        "print(\"best_PrivateTest_acc_epoch: %d\" % best_PrivateTest_acc_epoch)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}